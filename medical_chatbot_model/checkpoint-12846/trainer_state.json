{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 12846,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0077845243655612646,
      "grad_norm": 0.867158830165863,
      "learning_rate": 4.961077378172194e-05,
      "loss": 2.7812,
      "step": 100
    },
    {
      "epoch": 0.015569048731122529,
      "grad_norm": 0.9753636121749878,
      "learning_rate": 4.9221547563443875e-05,
      "loss": 2.5433,
      "step": 200
    },
    {
      "epoch": 0.023353573096683792,
      "grad_norm": 1.1419885158538818,
      "learning_rate": 4.883232134516581e-05,
      "loss": 2.4758,
      "step": 300
    },
    {
      "epoch": 0.031138097462245058,
      "grad_norm": 1.3434730768203735,
      "learning_rate": 4.844309512688775e-05,
      "loss": 2.4547,
      "step": 400
    },
    {
      "epoch": 0.03892262182780632,
      "grad_norm": 1.3308159112930298,
      "learning_rate": 4.8053868908609684e-05,
      "loss": 2.4573,
      "step": 500
    },
    {
      "epoch": 0.046707146193367584,
      "grad_norm": 1.3124771118164062,
      "learning_rate": 4.766464269033162e-05,
      "loss": 2.4265,
      "step": 600
    },
    {
      "epoch": 0.05449167055892885,
      "grad_norm": 1.5378121137619019,
      "learning_rate": 4.727541647205356e-05,
      "loss": 2.4529,
      "step": 700
    },
    {
      "epoch": 0.062276194924490116,
      "grad_norm": 1.552614450454712,
      "learning_rate": 4.68861902537755e-05,
      "loss": 2.3922,
      "step": 800
    },
    {
      "epoch": 0.07006071929005138,
      "grad_norm": 1.51328706741333,
      "learning_rate": 4.649696403549743e-05,
      "loss": 2.3839,
      "step": 900
    },
    {
      "epoch": 0.07784524365561264,
      "grad_norm": 1.8827664852142334,
      "learning_rate": 4.610773781721937e-05,
      "loss": 2.3473,
      "step": 1000
    },
    {
      "epoch": 0.0856297680211739,
      "grad_norm": 1.456146001815796,
      "learning_rate": 4.57185115989413e-05,
      "loss": 2.3472,
      "step": 1100
    },
    {
      "epoch": 0.09341429238673517,
      "grad_norm": 1.776398777961731,
      "learning_rate": 4.5329285380663246e-05,
      "loss": 2.3237,
      "step": 1200
    },
    {
      "epoch": 0.10119881675229643,
      "grad_norm": 1.6244986057281494,
      "learning_rate": 4.4940059162385176e-05,
      "loss": 2.3236,
      "step": 1300
    },
    {
      "epoch": 0.1089833411178577,
      "grad_norm": 2.1217846870422363,
      "learning_rate": 4.455083294410712e-05,
      "loss": 2.3131,
      "step": 1400
    },
    {
      "epoch": 0.11676786548341897,
      "grad_norm": 1.442710041999817,
      "learning_rate": 4.4161606725829055e-05,
      "loss": 2.258,
      "step": 1500
    },
    {
      "epoch": 0.12455238984898023,
      "grad_norm": 1.8718012571334839,
      "learning_rate": 4.377238050755099e-05,
      "loss": 2.2634,
      "step": 1600
    },
    {
      "epoch": 0.1323369142145415,
      "grad_norm": 1.6259067058563232,
      "learning_rate": 4.338315428927293e-05,
      "loss": 2.2465,
      "step": 1700
    },
    {
      "epoch": 0.14012143858010276,
      "grad_norm": 1.6524319648742676,
      "learning_rate": 4.2993928070994864e-05,
      "loss": 2.2133,
      "step": 1800
    },
    {
      "epoch": 0.14790596294566402,
      "grad_norm": 1.4076263904571533,
      "learning_rate": 4.26047018527168e-05,
      "loss": 2.2438,
      "step": 1900
    },
    {
      "epoch": 0.15569048731122528,
      "grad_norm": 1.453831672668457,
      "learning_rate": 4.221547563443874e-05,
      "loss": 2.2453,
      "step": 2000
    },
    {
      "epoch": 0.16347501167678655,
      "grad_norm": 1.4936686754226685,
      "learning_rate": 4.1826249416160674e-05,
      "loss": 2.206,
      "step": 2100
    },
    {
      "epoch": 0.1712595360423478,
      "grad_norm": 1.565687656402588,
      "learning_rate": 4.143702319788261e-05,
      "loss": 2.2288,
      "step": 2200
    },
    {
      "epoch": 0.17904406040790907,
      "grad_norm": 1.4193683862686157,
      "learning_rate": 4.1047796979604546e-05,
      "loss": 2.2038,
      "step": 2300
    },
    {
      "epoch": 0.18682858477347034,
      "grad_norm": 1.516798734664917,
      "learning_rate": 4.065857076132649e-05,
      "loss": 2.1924,
      "step": 2400
    },
    {
      "epoch": 0.1946131091390316,
      "grad_norm": 1.6315280199050903,
      "learning_rate": 4.026934454304842e-05,
      "loss": 2.1528,
      "step": 2500
    },
    {
      "epoch": 0.20239763350459286,
      "grad_norm": 1.5479421615600586,
      "learning_rate": 3.988011832477036e-05,
      "loss": 2.1642,
      "step": 2600
    },
    {
      "epoch": 0.21018215787015412,
      "grad_norm": 1.5507835149765015,
      "learning_rate": 3.949089210649229e-05,
      "loss": 2.2108,
      "step": 2700
    },
    {
      "epoch": 0.2179666822357154,
      "grad_norm": 1.5236421823501587,
      "learning_rate": 3.9101665888214235e-05,
      "loss": 2.1896,
      "step": 2800
    },
    {
      "epoch": 0.22575120660127665,
      "grad_norm": 1.4778269529342651,
      "learning_rate": 3.8712439669936165e-05,
      "loss": 2.1301,
      "step": 2900
    },
    {
      "epoch": 0.23353573096683794,
      "grad_norm": 1.6876299381256104,
      "learning_rate": 3.832321345165811e-05,
      "loss": 2.162,
      "step": 3000
    },
    {
      "epoch": 0.2413202553323992,
      "grad_norm": 1.9713337421417236,
      "learning_rate": 3.7933987233380044e-05,
      "loss": 2.1663,
      "step": 3100
    },
    {
      "epoch": 0.24910477969796047,
      "grad_norm": 1.6661475896835327,
      "learning_rate": 3.754476101510198e-05,
      "loss": 2.1955,
      "step": 3200
    },
    {
      "epoch": 0.25688930406352173,
      "grad_norm": 1.5690897703170776,
      "learning_rate": 3.715553479682392e-05,
      "loss": 2.1766,
      "step": 3300
    },
    {
      "epoch": 0.264673828429083,
      "grad_norm": 1.9188324213027954,
      "learning_rate": 3.6766308578545854e-05,
      "loss": 2.1901,
      "step": 3400
    },
    {
      "epoch": 0.27245835279464425,
      "grad_norm": 1.5956612825393677,
      "learning_rate": 3.637708236026779e-05,
      "loss": 2.2033,
      "step": 3500
    },
    {
      "epoch": 0.2802428771602055,
      "grad_norm": 1.6781245470046997,
      "learning_rate": 3.5987856141989726e-05,
      "loss": 2.2052,
      "step": 3600
    },
    {
      "epoch": 0.2880274015257668,
      "grad_norm": 1.700824499130249,
      "learning_rate": 3.559862992371166e-05,
      "loss": 2.1879,
      "step": 3700
    },
    {
      "epoch": 0.29581192589132804,
      "grad_norm": 1.5309349298477173,
      "learning_rate": 3.52094037054336e-05,
      "loss": 2.193,
      "step": 3800
    },
    {
      "epoch": 0.3035964502568893,
      "grad_norm": 1.956102967262268,
      "learning_rate": 3.4820177487155536e-05,
      "loss": 2.1826,
      "step": 3900
    },
    {
      "epoch": 0.31138097462245057,
      "grad_norm": 1.6857243776321411,
      "learning_rate": 3.443095126887747e-05,
      "loss": 2.1596,
      "step": 4000
    },
    {
      "epoch": 0.31916549898801183,
      "grad_norm": 1.8105846643447876,
      "learning_rate": 3.404172505059941e-05,
      "loss": 2.1701,
      "step": 4100
    },
    {
      "epoch": 0.3269500233535731,
      "grad_norm": 1.8186544179916382,
      "learning_rate": 3.3652498832321345e-05,
      "loss": 2.1797,
      "step": 4200
    },
    {
      "epoch": 0.33473454771913436,
      "grad_norm": 1.850948691368103,
      "learning_rate": 3.326327261404328e-05,
      "loss": 2.1475,
      "step": 4300
    },
    {
      "epoch": 0.3425190720846956,
      "grad_norm": 1.7049154043197632,
      "learning_rate": 3.287404639576522e-05,
      "loss": 2.1515,
      "step": 4400
    },
    {
      "epoch": 0.3503035964502569,
      "grad_norm": 1.8839282989501953,
      "learning_rate": 3.2484820177487154e-05,
      "loss": 2.164,
      "step": 4500
    },
    {
      "epoch": 0.35808812081581815,
      "grad_norm": 1.8068348169326782,
      "learning_rate": 3.209559395920909e-05,
      "loss": 2.1611,
      "step": 4600
    },
    {
      "epoch": 0.3658726451813794,
      "grad_norm": 1.477889060974121,
      "learning_rate": 3.1706367740931034e-05,
      "loss": 2.156,
      "step": 4700
    },
    {
      "epoch": 0.37365716954694067,
      "grad_norm": 1.74018132686615,
      "learning_rate": 3.131714152265296e-05,
      "loss": 2.1248,
      "step": 4800
    },
    {
      "epoch": 0.38144169391250193,
      "grad_norm": 1.640026569366455,
      "learning_rate": 3.0927915304374907e-05,
      "loss": 2.1794,
      "step": 4900
    },
    {
      "epoch": 0.3892262182780632,
      "grad_norm": 1.5925211906433105,
      "learning_rate": 3.0538689086096836e-05,
      "loss": 2.1351,
      "step": 5000
    },
    {
      "epoch": 0.39701074264362446,
      "grad_norm": 2.1736912727355957,
      "learning_rate": 3.014946286781878e-05,
      "loss": 2.1683,
      "step": 5100
    },
    {
      "epoch": 0.4047952670091857,
      "grad_norm": 1.7684670686721802,
      "learning_rate": 2.9760236649540712e-05,
      "loss": 2.1979,
      "step": 5200
    },
    {
      "epoch": 0.412579791374747,
      "grad_norm": 2.289945125579834,
      "learning_rate": 2.9371010431262652e-05,
      "loss": 2.1196,
      "step": 5300
    },
    {
      "epoch": 0.42036431574030825,
      "grad_norm": 1.5516570806503296,
      "learning_rate": 2.8981784212984585e-05,
      "loss": 2.1345,
      "step": 5400
    },
    {
      "epoch": 0.4281488401058695,
      "grad_norm": 2.2347428798675537,
      "learning_rate": 2.8592557994706525e-05,
      "loss": 2.152,
      "step": 5500
    },
    {
      "epoch": 0.4359333644714308,
      "grad_norm": 1.448586106300354,
      "learning_rate": 2.820333177642846e-05,
      "loss": 2.153,
      "step": 5600
    },
    {
      "epoch": 0.44371788883699204,
      "grad_norm": 2.067577838897705,
      "learning_rate": 2.78141055581504e-05,
      "loss": 2.1408,
      "step": 5700
    },
    {
      "epoch": 0.4515024132025533,
      "grad_norm": 2.181133985519409,
      "learning_rate": 2.7424879339872334e-05,
      "loss": 2.1323,
      "step": 5800
    },
    {
      "epoch": 0.45928693756811456,
      "grad_norm": 1.7618117332458496,
      "learning_rate": 2.7035653121594274e-05,
      "loss": 2.1979,
      "step": 5900
    },
    {
      "epoch": 0.4670714619336759,
      "grad_norm": 1.6940011978149414,
      "learning_rate": 2.6646426903316207e-05,
      "loss": 2.1522,
      "step": 6000
    },
    {
      "epoch": 0.47485598629923714,
      "grad_norm": 1.5922967195510864,
      "learning_rate": 2.6257200685038147e-05,
      "loss": 2.1471,
      "step": 6100
    },
    {
      "epoch": 0.4826405106647984,
      "grad_norm": 1.7801557779312134,
      "learning_rate": 2.586797446676008e-05,
      "loss": 2.1386,
      "step": 6200
    },
    {
      "epoch": 0.49042503503035967,
      "grad_norm": 1.643513560295105,
      "learning_rate": 2.547874824848202e-05,
      "loss": 2.1481,
      "step": 6300
    },
    {
      "epoch": 0.49820955939592093,
      "grad_norm": 1.7896980047225952,
      "learning_rate": 2.5089522030203956e-05,
      "loss": 2.1335,
      "step": 6400
    },
    {
      "epoch": 0.5059940837614821,
      "grad_norm": 1.5888679027557373,
      "learning_rate": 2.4700295811925892e-05,
      "loss": 2.1378,
      "step": 6500
    },
    {
      "epoch": 0.5137786081270435,
      "grad_norm": 1.82240891456604,
      "learning_rate": 2.431106959364783e-05,
      "loss": 2.1735,
      "step": 6600
    },
    {
      "epoch": 0.5215631324926047,
      "grad_norm": 1.7129701375961304,
      "learning_rate": 2.3921843375369765e-05,
      "loss": 2.1592,
      "step": 6700
    },
    {
      "epoch": 0.529347656858166,
      "grad_norm": 1.9636412858963013,
      "learning_rate": 2.35326171570917e-05,
      "loss": 2.1147,
      "step": 6800
    },
    {
      "epoch": 0.5371321812237272,
      "grad_norm": 1.7865546941757202,
      "learning_rate": 2.3143390938813638e-05,
      "loss": 2.1077,
      "step": 6900
    },
    {
      "epoch": 0.5449167055892885,
      "grad_norm": 2.106114625930786,
      "learning_rate": 2.2754164720535574e-05,
      "loss": 2.1628,
      "step": 7000
    },
    {
      "epoch": 0.5527012299548497,
      "grad_norm": 1.8816183805465698,
      "learning_rate": 2.2364938502257514e-05,
      "loss": 2.1804,
      "step": 7100
    },
    {
      "epoch": 0.560485754320411,
      "grad_norm": 1.6559325456619263,
      "learning_rate": 2.197571228397945e-05,
      "loss": 2.1072,
      "step": 7200
    },
    {
      "epoch": 0.5682702786859722,
      "grad_norm": 1.6648393869400024,
      "learning_rate": 2.1586486065701387e-05,
      "loss": 2.1374,
      "step": 7300
    },
    {
      "epoch": 0.5760548030515336,
      "grad_norm": 1.7424399852752686,
      "learning_rate": 2.1197259847423323e-05,
      "loss": 2.141,
      "step": 7400
    },
    {
      "epoch": 0.5838393274170948,
      "grad_norm": 1.770367980003357,
      "learning_rate": 2.080803362914526e-05,
      "loss": 2.1319,
      "step": 7500
    },
    {
      "epoch": 0.5916238517826561,
      "grad_norm": 1.765093445777893,
      "learning_rate": 2.0418807410867196e-05,
      "loss": 2.1356,
      "step": 7600
    },
    {
      "epoch": 0.5994083761482173,
      "grad_norm": 1.8193045854568481,
      "learning_rate": 2.0029581192589133e-05,
      "loss": 2.1243,
      "step": 7700
    },
    {
      "epoch": 0.6071929005137786,
      "grad_norm": 1.9875048398971558,
      "learning_rate": 1.964035497431107e-05,
      "loss": 2.1266,
      "step": 7800
    },
    {
      "epoch": 0.6149774248793398,
      "grad_norm": 1.8264366388320923,
      "learning_rate": 1.925112875603301e-05,
      "loss": 2.1238,
      "step": 7900
    },
    {
      "epoch": 0.6227619492449011,
      "grad_norm": 1.5446016788482666,
      "learning_rate": 1.8861902537754945e-05,
      "loss": 2.0992,
      "step": 8000
    },
    {
      "epoch": 0.6305464736104625,
      "grad_norm": 1.8150718212127686,
      "learning_rate": 1.847267631947688e-05,
      "loss": 2.0975,
      "step": 8100
    },
    {
      "epoch": 0.6383309979760237,
      "grad_norm": 1.9519928693771362,
      "learning_rate": 1.8083450101198818e-05,
      "loss": 2.1441,
      "step": 8200
    },
    {
      "epoch": 0.646115522341585,
      "grad_norm": 2.1359527111053467,
      "learning_rate": 1.7694223882920754e-05,
      "loss": 2.1195,
      "step": 8300
    },
    {
      "epoch": 0.6539000467071462,
      "grad_norm": 1.7831110954284668,
      "learning_rate": 1.730499766464269e-05,
      "loss": 2.1291,
      "step": 8400
    },
    {
      "epoch": 0.6616845710727075,
      "grad_norm": 1.8171005249023438,
      "learning_rate": 1.6915771446364627e-05,
      "loss": 2.1325,
      "step": 8500
    },
    {
      "epoch": 0.6694690954382687,
      "grad_norm": 1.8319673538208008,
      "learning_rate": 1.6526545228086564e-05,
      "loss": 2.1622,
      "step": 8600
    },
    {
      "epoch": 0.67725361980383,
      "grad_norm": 1.8119146823883057,
      "learning_rate": 1.6137319009808503e-05,
      "loss": 2.108,
      "step": 8700
    },
    {
      "epoch": 0.6850381441693912,
      "grad_norm": 1.7705243825912476,
      "learning_rate": 1.574809279153044e-05,
      "loss": 2.142,
      "step": 8800
    },
    {
      "epoch": 0.6928226685349526,
      "grad_norm": 2.058109760284424,
      "learning_rate": 1.5358866573252376e-05,
      "loss": 2.1576,
      "step": 8900
    },
    {
      "epoch": 0.7006071929005138,
      "grad_norm": 1.9237656593322754,
      "learning_rate": 1.4969640354974313e-05,
      "loss": 2.1436,
      "step": 9000
    },
    {
      "epoch": 0.7083917172660751,
      "grad_norm": 1.9999516010284424,
      "learning_rate": 1.4580414136696249e-05,
      "loss": 2.1509,
      "step": 9100
    },
    {
      "epoch": 0.7161762416316363,
      "grad_norm": 1.5607868432998657,
      "learning_rate": 1.4191187918418185e-05,
      "loss": 2.1463,
      "step": 9200
    },
    {
      "epoch": 0.7239607659971976,
      "grad_norm": 1.7072590589523315,
      "learning_rate": 1.3801961700140124e-05,
      "loss": 2.1248,
      "step": 9300
    },
    {
      "epoch": 0.7317452903627588,
      "grad_norm": 1.5668836832046509,
      "learning_rate": 1.341273548186206e-05,
      "loss": 2.1098,
      "step": 9400
    },
    {
      "epoch": 0.7395298147283201,
      "grad_norm": 1.8577234745025635,
      "learning_rate": 1.3023509263583996e-05,
      "loss": 2.1112,
      "step": 9500
    },
    {
      "epoch": 0.7473143390938813,
      "grad_norm": 1.8670899868011475,
      "learning_rate": 1.2634283045305933e-05,
      "loss": 2.1025,
      "step": 9600
    },
    {
      "epoch": 0.7550988634594427,
      "grad_norm": 1.677627682685852,
      "learning_rate": 1.2245056827027869e-05,
      "loss": 2.0977,
      "step": 9700
    },
    {
      "epoch": 0.7628833878250039,
      "grad_norm": 1.8580001592636108,
      "learning_rate": 1.1855830608749806e-05,
      "loss": 2.1343,
      "step": 9800
    },
    {
      "epoch": 0.7706679121905652,
      "grad_norm": 1.8727655410766602,
      "learning_rate": 1.1466604390471742e-05,
      "loss": 2.1158,
      "step": 9900
    },
    {
      "epoch": 0.7784524365561264,
      "grad_norm": 1.8314779996871948,
      "learning_rate": 1.107737817219368e-05,
      "loss": 2.0978,
      "step": 10000
    },
    {
      "epoch": 0.7862369609216877,
      "grad_norm": 1.7139663696289062,
      "learning_rate": 1.0688151953915616e-05,
      "loss": 2.0786,
      "step": 10100
    },
    {
      "epoch": 0.7940214852872489,
      "grad_norm": 1.9043774604797363,
      "learning_rate": 1.0298925735637553e-05,
      "loss": 2.1026,
      "step": 10200
    },
    {
      "epoch": 0.8018060096528102,
      "grad_norm": 2.0198450088500977,
      "learning_rate": 9.90969951735949e-06,
      "loss": 2.1046,
      "step": 10300
    },
    {
      "epoch": 0.8095905340183714,
      "grad_norm": 2.0085694789886475,
      "learning_rate": 9.520473299081427e-06,
      "loss": 2.1133,
      "step": 10400
    },
    {
      "epoch": 0.8173750583839328,
      "grad_norm": 2.1208133697509766,
      "learning_rate": 9.131247080803364e-06,
      "loss": 2.0629,
      "step": 10500
    },
    {
      "epoch": 0.825159582749494,
      "grad_norm": 2.4850242137908936,
      "learning_rate": 8.7420208625253e-06,
      "loss": 2.1475,
      "step": 10600
    },
    {
      "epoch": 0.8329441071150553,
      "grad_norm": 1.7366111278533936,
      "learning_rate": 8.352794644247237e-06,
      "loss": 2.1389,
      "step": 10700
    },
    {
      "epoch": 0.8407286314806165,
      "grad_norm": 1.748998999595642,
      "learning_rate": 7.963568425969175e-06,
      "loss": 2.1273,
      "step": 10800
    },
    {
      "epoch": 0.8485131558461778,
      "grad_norm": 2.1295084953308105,
      "learning_rate": 7.574342207691111e-06,
      "loss": 2.1231,
      "step": 10900
    },
    {
      "epoch": 0.856297680211739,
      "grad_norm": 2.595163583755493,
      "learning_rate": 7.185115989413047e-06,
      "loss": 2.1401,
      "step": 11000
    },
    {
      "epoch": 0.8640822045773003,
      "grad_norm": 2.3250858783721924,
      "learning_rate": 6.795889771134983e-06,
      "loss": 2.1116,
      "step": 11100
    },
    {
      "epoch": 0.8718667289428615,
      "grad_norm": 1.8933717012405396,
      "learning_rate": 6.40666355285692e-06,
      "loss": 2.1172,
      "step": 11200
    },
    {
      "epoch": 0.8796512533084229,
      "grad_norm": 2.6591687202453613,
      "learning_rate": 6.0174373345788575e-06,
      "loss": 2.1037,
      "step": 11300
    },
    {
      "epoch": 0.8874357776739841,
      "grad_norm": 2.018068313598633,
      "learning_rate": 5.628211116300795e-06,
      "loss": 2.1022,
      "step": 11400
    },
    {
      "epoch": 0.8952203020395454,
      "grad_norm": 2.038625717163086,
      "learning_rate": 5.23898489802273e-06,
      "loss": 2.1036,
      "step": 11500
    },
    {
      "epoch": 0.9030048264051066,
      "grad_norm": 1.5893882513046265,
      "learning_rate": 4.849758679744668e-06,
      "loss": 2.1202,
      "step": 11600
    },
    {
      "epoch": 0.9107893507706679,
      "grad_norm": 2.041590929031372,
      "learning_rate": 4.460532461466604e-06,
      "loss": 2.0841,
      "step": 11700
    },
    {
      "epoch": 0.9185738751362291,
      "grad_norm": 1.7334567308425903,
      "learning_rate": 4.071306243188541e-06,
      "loss": 2.1325,
      "step": 11800
    },
    {
      "epoch": 0.9263583995017904,
      "grad_norm": 1.5436373949050903,
      "learning_rate": 3.682080024910478e-06,
      "loss": 2.0909,
      "step": 11900
    },
    {
      "epoch": 0.9341429238673518,
      "grad_norm": 2.13098406791687,
      "learning_rate": 3.292853806632415e-06,
      "loss": 2.1492,
      "step": 12000
    },
    {
      "epoch": 0.941927448232913,
      "grad_norm": 2.2315101623535156,
      "learning_rate": 2.9036275883543517e-06,
      "loss": 2.0867,
      "step": 12100
    },
    {
      "epoch": 0.9497119725984743,
      "grad_norm": 1.950704574584961,
      "learning_rate": 2.5144013700762886e-06,
      "loss": 2.1229,
      "step": 12200
    },
    {
      "epoch": 0.9574964969640355,
      "grad_norm": 2.342024564743042,
      "learning_rate": 2.125175151798225e-06,
      "loss": 2.0779,
      "step": 12300
    },
    {
      "epoch": 0.9652810213295968,
      "grad_norm": 2.408572196960449,
      "learning_rate": 1.735948933520162e-06,
      "loss": 2.1282,
      "step": 12400
    },
    {
      "epoch": 0.973065545695158,
      "grad_norm": 1.9107996225357056,
      "learning_rate": 1.3467227152420988e-06,
      "loss": 2.0931,
      "step": 12500
    },
    {
      "epoch": 0.9808500700607193,
      "grad_norm": 2.115292549133301,
      "learning_rate": 9.574964969640354e-07,
      "loss": 2.1268,
      "step": 12600
    },
    {
      "epoch": 0.9886345944262805,
      "grad_norm": 1.7333614826202393,
      "learning_rate": 5.682702786859723e-07,
      "loss": 2.0569,
      "step": 12700
    },
    {
      "epoch": 0.9964191187918419,
      "grad_norm": 1.9279526472091675,
      "learning_rate": 1.7904406040790908e-07,
      "loss": 2.1577,
      "step": 12800
    }
  ],
  "logging_steps": 100,
  "max_steps": 12846,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3834307964030157e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
